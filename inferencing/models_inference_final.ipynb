{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251b1095",
   "metadata": {},
   "source": [
    "## Closing Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Predicted Close Price for 2022-06-02: 74.70\n",
      "📊 Predicted Trend: Downtrend\n",
      "🔒 Confidence Score: 100.0\n",
      "Volatility: 3.90\n",
      "💡 Recommendation: Sell\n",
      "📁 Saved prediction with recommendation as 'predicted_next_day_price.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# 1. Define Transformer model\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(1), :]\n",
    "\n",
    "class StockGenWithSentimentProbs(nn.Module):\n",
    "    def __init__(self, input_dim=10, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, 64)\n",
    "        self.positional_encoding = PositionalEncoding(d_model=64)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=64, nhead=4, dim_feedforward=128, dropout=0.1, activation='gelu'),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(64)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.layer_norm(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.fc(x).squeeze(-1)\n",
    "\n",
    "# 2. Load data and model\n",
    "df = pd.read_csv(\"sentiment_data_news_ctsh.csv\")\n",
    "# Compute volatility: max(close_t-1 to t-7) - min(close_t-1 to t-7)\n",
    "def compute_volatility(row):\n",
    "    try:\n",
    "        close_prices = [row[f\"Close_t-{t}\"] for t in range(1, 8)]\n",
    "        return max(close_prices) - min(close_prices)\n",
    "    except:\n",
    "        return 0.0  # Default to 0 if any error\n",
    "\n",
    "# Apply to dataframe\n",
    "df[\"Volatility\"] = df.apply(compute_volatility, axis=1)\n",
    "\n",
    "scaler = joblib.load(\"stock_global_scaler.pkl\")\n",
    "ticker = df['Ticker'].iloc[0]\n",
    "df[\"Close\"] = scaler.transform(df[[\"Close\"]])\n",
    "\n",
    "# 3. Feature engineering\n",
    "for lag in range(1, 8):\n",
    "    df[f\"Close_t-{lag}\"] = df[\"Close\"].shift(lag)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 4. Prepare sequence\n",
    "feature_columns = [f\"Close_t-{i}\" for i in range(1, 8)] + [\"FinBERT_neutral\", \"FinBERT_positive\", \"FinBERT_negative\"]\n",
    "sequence = [[row[col] for col in feature_columns] for _, row in df.iterrows()]\n",
    "X = torch.tensor([sequence], dtype=torch.float32)\n",
    "\n",
    "# 5. Load transformer model and predict\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = StockGenWithSentimentProbs(input_dim=10, num_layers=4).to(device)\n",
    "model.load_state_dict(torch.load(\"stock_model_with_probs.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_change = model(X.to(device)).item()\n",
    "\n",
    "last_close_scaled = df.iloc[-1][\"Close_t-1\"]\n",
    "last_close_unscaled = scaler.inverse_transform([[last_close_scaled]])[0][0]\n",
    "predicted_price = last_close_unscaled + predicted_change\n",
    "\n",
    "# 6. Determine predicted trend\n",
    "delta = predicted_price - last_close_unscaled\n",
    "threshold = 0\n",
    "if delta > threshold:\n",
    "    predicted_trend = \"Uptrend\"\n",
    "elif delta < -threshold:\n",
    "    predicted_trend = \"Downtrend\"\n",
    "else:\n",
    "    predicted_trend = \"Sideways\"\n",
    "\n",
    "# 7. Determine prediction date\n",
    "last_date_str = df.iloc[-1][\"Date\"]\n",
    "last_date = datetime.strptime(last_date_str, \"%Y-%m-%d\")\n",
    "next_date = last_date + timedelta(days=1)\n",
    "\n",
    "# 8. Use entire CSV + prediction to infer confidence\n",
    "# Load tokenizer and PEFT model\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "peft_model = PeftModel.from_pretrained(base_model, \"./finetuned_lora_model_confidence\").to(device)\n",
    "peft_model.eval()\n",
    "\n",
    "# Construct a single inference prompt\n",
    "input_text = (\n",
    "    f\"You are a financial analyst model evaluating prediction reliability.\\n\"\n",
    "    f\"Ticker: {ticker}\\n\"\n",
    "    f\"Past Data: {df[feature_columns + ['Close']].tail(10).to_dict(orient='records')}\\n\"\n",
    "    f\"Predicted Close: {predicted_price:.2f}\\n\"\n",
    "    f\"Predicted Trend: {predicted_trend}\\n\"\n",
    "    f\"Last Known Close: {last_close_unscaled:.2f}\\n\"\n",
    "    f\"Please return a confidence score (0-1) for this prediction.\"\n",
    ")\n",
    "\n",
    "# Tokenize and predict confidence\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "with torch.no_grad():\n",
    "    output_ids = peft_model.generate(\n",
    "        **inputs,\n",
    "        max_length=16,\n",
    "        temperature=0.7,    \n",
    "        top_p=0.9,           \n",
    "        do_sample=True       \n",
    "    )   \n",
    "    confidence_score = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "last_volatility = df[\"Volatility\"].iloc[-1]\n",
    "\n",
    "# 9. Generate recommendation using fine-tuned model\n",
    "# Load recommendation model\n",
    "peft_model_recommendation = PeftModel.from_pretrained(base_model, \"./finetuned_lora_model_recommendation\").to(device)\n",
    "peft_model_recommendation.eval()\n",
    "\n",
    "# Construct recommendation prompt\n",
    "recommendation_input_text = (\n",
    "    f\"You are a financial assistant model. Based on the following data, provide a stock recommendation (Buy, Sell, Hold):\\n\"\n",
    "    f\"Predicted Trend: {predicted_trend}\\n\"\n",
    "    f\"Confidence: {confidence_score}\\n\"\n",
    "    f\"Volatility: {last_volatility:.2f}\\n\"\n",
    "    f\"Predicted Close: {predicted_price:.2f}\\n\"\n",
    "    f\"Past 7-Day Closing Prices: {df[feature_columns].tail(7).to_dict(orient='records')}\\n\"\n",
    "    f\"Recommendation (Buy, Sell, Hold):\"\n",
    ")\n",
    "\n",
    "# Tokenize and predict recommendation\n",
    "inputs_recommendation = tokenizer(recommendation_input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "with torch.no_grad():\n",
    "    output_ids_recommendation = peft_model_recommendation.generate(\n",
    "        **inputs_recommendation,\n",
    "        max_length=8,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "    predicted_recommendation = tokenizer.decode(output_ids_recommendation[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# 10. Save prediction with recommendation\n",
    "prediction_row = {\n",
    "    \"Date\": next_date.strftime(\"%Y-%m-%d\"),\n",
    "    \"Ticker\": ticker,\n",
    "    \"Last_Close\": last_close_unscaled,\n",
    "    \"Predicted_Close_Next_Day\": predicted_price,\n",
    "    \"Predicted_Trend\": predicted_trend,\n",
    "    \"Predicted_Confidence\": confidence_score,\n",
    "    \"Last_Volatility\": last_volatility,\n",
    "    \"Predicted_Recommendation\": predicted_recommendation\n",
    "}\n",
    "prediction_df = pd.DataFrame([prediction_row])\n",
    "prediction_df.to_csv(\"predicted_next_day_price.csv\", index=False)\n",
    "\n",
    "# 11. Output\n",
    "print(f\"\\n📈 Predicted Close Price for {next_date.strftime('%Y-%m-%d')}: ${predicted_price:.2f}\")\n",
    "print(f\"📊 Predicted Trend: {predicted_trend}\")\n",
    "print(f\"🔒 Confidence Score: {confidence_score}\")\n",
    "print(f\"Volatility: {last_volatility:.2f}\")\n",
    "print(f\"💡 Recommendation: {predicted_recommendation}\")\n",
    "print(\"📁 Saved prediction with recommendation as 'predicted_next_day_price.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
